{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Imbalanced learning tools\n",
    "# If you don't have it installed: pip install imbalanced-learn\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (0=legit, 1=fraud):\n",
      "        count  percent\n",
      "fraud                 \n",
      "0      912597    91.26\n",
      "1       87403     8.74\n",
      "\n",
      "Imbalanced dataset detected: fraud class is ~8.740% of data.\n",
      "\n",
      "=== Baseline LogisticRegression ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      "[[181296   1223]\n",
      " [  6895  10586]]\n",
      "\n",
      "Fraud class (1) metrics:\n",
      "Precision: 0.8964\n",
      "Recall   : 0.6056\n",
      "F1-score : 0.7228\n",
      "\n",
      "ROC-AUC  : 0.9670\n",
      "PR-AUC   : 0.8072   (recommended for imbalanced data)\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9634    0.9933    0.9781    182519\n",
      "           1     0.8964    0.6056    0.7228     17481\n",
      "\n",
      "    accuracy                         0.9594    200000\n",
      "   macro avg     0.9299    0.7994    0.8505    200000\n",
      "weighted avg     0.9575    0.9594    0.9558    200000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== RandomOverSampler + LogisticRegression ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      "[[170390  12129]\n",
      " [   911  16570]]\n",
      "\n",
      "Fraud class (1) metrics:\n",
      "Precision: 0.5774\n",
      "Recall   : 0.9479\n",
      "F1-score : 0.7176\n",
      "\n",
      "ROC-AUC  : 0.9795\n",
      "PR-AUC   : 0.7574   (recommended for imbalanced data)\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9947    0.9335    0.9631    182519\n",
      "           1     0.5774    0.9479    0.7176     17481\n",
      "\n",
      "    accuracy                         0.9348    200000\n",
      "   macro avg     0.7860    0.9407    0.8404    200000\n",
      "weighted avg     0.9582    0.9348    0.9417    200000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== RandomUnderSampler + LogisticRegression ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      "[[170394  12125]\n",
      " [   918  16563]]\n",
      "\n",
      "Fraud class (1) metrics:\n",
      "Precision: 0.5773\n",
      "Recall   : 0.9475\n",
      "F1-score : 0.7175\n",
      "\n",
      "ROC-AUC  : 0.9796\n",
      "PR-AUC   : 0.7569   (recommended for imbalanced data)\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9946    0.9336    0.9631    182519\n",
      "           1     0.5773    0.9475    0.7175     17481\n",
      "\n",
      "    accuracy                         0.9348    200000\n",
      "   macro avg     0.7860    0.9405    0.8403    200000\n",
      "weighted avg     0.9582    0.9348    0.9417    200000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== SMOTE + LogisticRegression ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      "[[170386  12133]\n",
      " [   907  16574]]\n",
      "\n",
      "Fraud class (1) metrics:\n",
      "Precision: 0.5774\n",
      "Recall   : 0.9481\n",
      "F1-score : 0.7177\n",
      "\n",
      "ROC-AUC  : 0.9795\n",
      "PR-AUC   : 0.7574   (recommended for imbalanced data)\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9947    0.9335    0.9631    182519\n",
      "           1     0.5774    0.9481    0.7177     17481\n",
      "\n",
      "    accuracy                         0.9348    200000\n",
      "   macro avg     0.7860    0.9408    0.8404    200000\n",
      "weighted avg     0.9582    0.9348    0.9417    200000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==== Summary (sorted by PR-AUC) ====\n",
      "                                     model  precision_fraud  recall_fraud  \\\n",
      "0              Baseline LogisticRegression           0.8964        0.6056   \n",
      "1   RandomOverSampler + LogisticRegression           0.5774        0.9479   \n",
      "3               SMOTE + LogisticRegression           0.5774        0.9481   \n",
      "2  RandomUnderSampler + LogisticRegression           0.5773        0.9475   \n",
      "\n",
      "   f1_fraud  roc_auc  pr_auc  \n",
      "0    0.7228   0.9670  0.8072  \n",
      "1    0.7176   0.9795  0.7574  \n",
      "3    0.7177   0.9795  0.7574  \n",
      "2    0.7175   0.9796  0.7569  \n",
      "\n",
      "Interpretation guidance:\n",
      "- For imbalanced problems, PR-AUC and Recall/F1 on the fraud class are often more informative than accuracy.\n",
      "- Oversampling/SMOTE typically increases recall (catches more fraud) but may reduce precision (more false alarms).\n",
      "- Undersampling can simplify learning but may lose important majority-class information.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "TARGET = \"fraud\"\n",
    "\n",
    "assert TARGET in df.columns, f\"Target column '{TARGET}' not found.\"\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "\n",
    "counts = y.value_counts().sort_index()\n",
    "pct = y.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"Target distribution (0=legit, 1=fraud):\")\n",
    "print(pd.DataFrame({\"count\": counts, \"percent\": pct.round(3)}))\n",
    "print()\n",
    "\n",
    "minority_pct = pct.loc[1] if 1 in pct.index else 0\n",
    "if minority_pct < 20:\n",
    "    print(f\"Imbalanced dataset detected: fraud class is ~{minority_pct:.3f}% of data.\\n\")\n",
    "else:\n",
    "    print(\"Dataset does not appear strongly imbalanced.\\n\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Prints metrics suitable for imbalanced classification.\n",
    "    Focus: minority (fraud=1) precision/recall/F1 + PR-AUC.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = None\n",
    "\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=None, labels=[0, 1]\n",
    "    )\n",
    "    p1, r1, f1_1 = precision[1], recall[1], f1[1]\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Confusion matrix [ [TN FP], [FN TP] ]:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(f\"\\nFraud class (1) metrics:\")\n",
    "    print(f\"Precision: {p1:.4f}\")\n",
    "    print(f\"Recall   : {r1:.4f}\")\n",
    "    print(f\"F1-score : {f1_1:.4f}\")\n",
    "\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        pr_auc = average_precision_score(y_test, y_proba)  # PR-AUC (Average Precision)\n",
    "        print(f\"\\nROC-AUC  : {roc_auc:.4f}\")\n",
    "        print(f\"PR-AUC   : {pr_auc:.4f}   (recommended for imbalanced data)\")\n",
    "    else:\n",
    "        print(\"\\nROC-AUC / PR-AUC not available (no probabilities).\")\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"-\" * 60)\n",
    "    print()\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"precision_fraud\": p1,\n",
    "        \"recall_fraud\": r1,\n",
    "        \"f1_fraud\": f1_1,\n",
    "        \"roc_auc\": roc_auc if y_proba is not None else np.nan,\n",
    "        \"pr_auc\": pr_auc if y_proba is not None else np.nan\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, solver=\"lbfgs\")  # baseline LR\n",
    "\n",
    "\n",
    "baseline_pipeline = ImbPipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", clf)\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "baseline_results = evaluate_model(\"Baseline LogisticRegression\", baseline_pipeline, X_test, y_test)\n",
    "\n",
    "\n",
    "oversample_pipeline = ImbPipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sampler\", RandomOverSampler(random_state=42)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "oversample_pipeline.fit(X_train, y_train)\n",
    "over_results = evaluate_model(\"RandomOverSampler + LogisticRegression\", oversample_pipeline, X_test, y_test)\n",
    "\n",
    "\n",
    "undersample_pipeline = ImbPipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sampler\", RandomUnderSampler(random_state=42)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "undersample_pipeline.fit(X_train, y_train)\n",
    "under_results = evaluate_model(\"RandomUnderSampler + LogisticRegression\", undersample_pipeline, X_test, y_test)\n",
    "\n",
    "\n",
    "smote_pipeline = ImbPipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sampler\", SMOTE(random_state=42, k_neighbors=5)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "smote_pipeline.fit(X_train, y_train)\n",
    "smote_results = evaluate_model(\"SMOTE + LogisticRegression\", smote_pipeline, X_test, y_test)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame([baseline_results, over_results, under_results, smote_results])\n",
    "summary = summary.sort_values(by=\"pr_auc\", ascending=False)\n",
    "\n",
    "print(\"==== Summary (sorted by PR-AUC) ====\")\n",
    "print(summary[[\"model\", \"precision_fraud\", \"recall_fraud\", \"f1_fraud\", \"roc_auc\", \"pr_auc\"]].round(4))\n",
    "print()\n",
    "\n",
    "print(\"Interpretation guidance:\")\n",
    "print(\"- For imbalanced problems, PR-AUC and Recall/F1 on the fraud class are often more informative than accuracy.\")\n",
    "print(\"- Oversampling/SMOTE typically increases recall (catches more fraud) but may reduce precision (more false alarms).\")\n",
    "print(\"- Undersampling can simplify learning but may lose important majority-class information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion:\n",
    "\n",
    "The dataset is highly imbalanced, with only 8.74% fraudulent transactions.\n",
    "\n",
    "The baseline Logistic Regression model achieved high precision (0.896) but lower recall (0.606),\n",
    "meaning many fraud cases were missed.\n",
    "\n",
    "After applying Oversampling, Undersampling, and SMOTE, recall increased significantly (~0.95),\n",
    "allowing the model to detect most fraud cases, but precision decreased (~0.58), resulting in more false positives.\n",
    "\n",
    "PR-AUC was highest for the baseline model (0.807), while resampling methods achieved slightly lower PR-AUC (~0.757).\n",
    "\n",
    "This shows a trade-off:\n",
    "- Baseline model is better when minimizing false alarms.\n",
    "- Resampling models are better when maximizing fraud detection.\n",
    "\n",
    "Depending on business priorities, SMOTE or oversampling may be preferred if catching fraud is more important than precision.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
